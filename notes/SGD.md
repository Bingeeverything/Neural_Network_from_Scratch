Stochastic Gradient Descent is what actuallty helps the network, learn by correcting the [[Loss]]
by teling us how to change our weights and biases
there is n which is a constant learning rate, which tells how fast are we learning
and we are just subtracting it from w1. which then tells does loss decrease, if it does, then it means, its gertting better, because if less loss more better predictions

Process of leanring would just be, going one sample at a time and learning 
calculating the partial derivates respective to the weights and biases
update each weight and bias
and continue